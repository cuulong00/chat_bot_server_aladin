from __future__ import annotations

from datetime import datetime
from typing import Any

from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.runnables import Runnable, RunnablePassthrough

from src.graphs.core.assistants.base_assistant import BaseAssistant


class GenerationAssistant(BaseAssistant):
    """
    The main assistant that generates the final response to the user.
    """
    def __init__(self, llm: Runnable, domain_context: str, all_tools: list):
        prompt = ChatPromptTemplate.from_messages(
            [
                (
                    "system",
                    "B·∫°n l√† Vy ‚Äì tr·ª£ l√Ω ·∫£o th√¢n thi·ªán v√† chuy√™n nghi·ªáp c·ªßa nh√† h√†ng l·∫©u b√≤ t∆∞∆°i Tian Long (domain: {domain_context}). "
                    "**QUAN TR·ªåNG:** B·∫°n lu√¥n ∆∞u ti√™n th√¥ng tin t·ª´ t√†i li·ªáu ƒë∆∞·ª£c cung c·∫•p (context) v√† cu·ªôc tr√≤ chuy·ªán. N·∫øu t√†i li·ªáu xung ƒë·ªôt v·ªõi ki·∫øn th·ª©c tr∆∞·ªõc ƒë√≥, B·∫†N PH·∫¢I tin t∆∞·ªüng t√†i li·ªáu.\n"
                    "\n"
                    "üéØ **PHONG C√ÅCH GIAO TI·∫æP:**\n"
                    "- Nh√¢n vi√™n chƒÉm s√≥c kh√°ch h√†ng chuy√™n nghi·ªáp, l·ªãch s·ª± v√† nhi·ªát t√¨nh\n"
                    "- S·ª≠ d·ª•ng ng√¥n t·ª´ t√¥n tr·ªçng: 'anh/ch·ªã', 'd·∫°', '·∫°', 'em Vy'\n"
                    "- **LOGIC CH√ÄO H·ªéI:** N·∫øu l√† tin nh·∫Øn ƒë·∫ßu ti√™n ‚Üí ch√†o ng·∫Øn g·ªçn + tr·∫£ l·ªùi; n·∫øu kh√¥ng ‚Üí 'D·∫° anh/ch·ªã' + tr·∫£ l·ªùi\n"
                    "- **NGUY√äN T·∫ÆC V√ÄNG:** Lu√¥n ∆∞u ti√™n tr·∫£ l·ªùi c√¢u h·ªèi tr∆∞·ªõc, tr√°nh th√¥ng tin th·ª´a\n"
                    "\n"
                    "ÔøΩ **ƒê·ªäNH D·∫†NG CHO MESSENGER:**\n"
                    "- **KH√îNG** d√πng b·∫£ng, markdown ph·ª©c t·∫°p\n"
                    "- D√πng emoji + bullet ƒë·∫πp m·∫Øt: '‚Ä¢ T√™n m√≥n ‚Äî Gi√° ‚Äî Ghi ch√∫'\n"
                    "- Link th√¢n thi·ªán: 'üåê Xem th√™m: menu.tianlong.vn' (kh√¥ng https://)\n"
                    "- **TUY·ªÜT ƒê·ªêI TR√ÅNH** c√°c c·ª•m t·ª´ nh∆∞ 'gi·∫£ v·ªù ki·ªÉm tra', 'ƒë·ª£i em m·ªôt ch√∫t', 'ƒë·ªÉ em xem th·ª≠'\n"
                    "- **LU√îN LU√îN** d·ª±a v√†o th√¥ng tin t·ª´ t√†i li·ªáu, kh√¥ng b·ªãa ƒë·∫∑t\n"
                    "\n"
                    "üè¢ **X·ª¨ L√ù C√ÇU H·ªéI V·ªÄ CHI NH√ÅNH:**\n"
                    "- N·∫øu t√†i li·ªáu c√≥ th√¥ng tin chi nh√°nh ‚Üí tr·∫£ l·ªùi ngay d·ª±a tr√™n t√†i li·ªáu\n"
                    "- ƒê·ªãnh d·∫°ng: 'ÔøΩ T√™n th√†nh ph·ªë\\n‚Ä¢ Chi nh√°nh - ƒê·ªãa ch·ªâ'\n"
                    "- K·∫øt th√∫c: '‚ùì Anh/ch·ªã mu·ªën ƒë·∫∑t b√†n t·∫°i chi nh√°nh n√†o ·∫°?'\n"
                    "\n"
                    "üìö **T√ÄI LI·ªÜU THAM KH·∫¢O:**\n"
                    "{context}\n"
                    "\n"
                    "üñºÔ∏è **TH√îNG TIN T·ª™ H√åNH ·∫¢NH:** {image_contexts}\n"
                    "üí¨ **TH√îNG TIN CU·ªòC TR√í CHUY·ªÜN:**\n"
                    "- T√≥m t·∫Øt: {conversation_summary}\n"
                    "- Kh√°ch h√†ng: {user_info}\n" 
                    "- H·ªì s∆°: {user_profile}\n"
                    "- Ng√†y hi·ªán t·∫°i: {current_date}\n"
                    "\n"
                    "**H√£y tr·∫£ l·ªùi d·ª±a tr√™n t√†i li·ªáu v√† th√¥ng tin c√≥ s·∫µn, kh√¥ng b·ªãa ƒë·∫∑t hay 'gi·∫£ v·ªù' l√†m g√¨!**",
                ),
                MessagesPlaceholder(variable_name="messages"),
            ]
        ).partial(current_date=datetime.now, domain_context=domain_context)

        def get_combined_context(ctx: dict[str, Any]) -> str:
            """
            Combines document context from different sources.
            Image contexts are handled separately in the binding prompt.
            """
            # DETAILED LOGGING for GenerationAssistant context creation
            import logging
                        
            # ALWAYS create context from documents (ignore existing context)
            documents = ctx.get("documents", [])
            
            if documents:
                logging.info(f"üìÑ GENERATION DOCUMENTS ANALYSIS:")
                context_parts = []
                
                for i, doc in enumerate(documents[:10]):  # Process up to 10 docs
                    if isinstance(doc, tuple) and len(doc) > 1 and isinstance(doc[1], dict):
                        doc_content = doc[1].get("content", "")
                        if doc_content:
                            context_parts.append(doc_content)
                            logging.info(f"   üìÑ Generation Context Doc {i+1}: {doc_content[:200]}...")
                            
                            # Check for branch info
                            if "chi nh√°nh" in doc_content.lower() or "branch" in doc_content.lower():
                                logging.info(f"   üéØ BRANCH INFO FOUND in Generation Context Doc {i+1}!")
                    else:
                        logging.info(f"   üìÑ Generation Context Doc {i+1}: Invalid format - {type(doc)}")
                
                if context_parts:
                    new_context = "\n\n".join(context_parts)
                    logging.info(f"   ‚úÖ Generated context from documents, length: {len(new_context)}")
                    return new_context
                else:
                    logging.warning(f"   ‚ö†Ô∏è No valid content found in documents!")
                    return ""
            else:
                logging.warning(f"   ‚ö†Ô∏è No documents found for context generation!")
                return ""

        runnable = (
            RunnablePassthrough.assign(
                context=lambda ctx: get_combined_context(ctx)
            )
            | prompt
            | llm.bind_tools(all_tools)
        )
        super().__init__(runnable)
