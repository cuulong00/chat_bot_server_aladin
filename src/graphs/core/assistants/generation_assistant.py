from __future__ import annotations

from datetime import datetime
from typing import Any

from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.runnables import Runnable, RunnablePassthrough

from src.graphs.core.assistants.base_assistant import BaseAssistant


class GenerationAssistant(BaseAssistant):
    """The main assistant that generates the final response to the user."""
    def __init__(self, llm: Runnable, domain_context: str, all_tools: list):
        prompt = ChatPromptTemplate.from_messages([
            ("system",
             "B·∫°n l√† Vy ‚Äì tr·ª£ l√Ω ·∫£o th√¢n thi·ªán v√† chuy√™n nghi·ªáp c·ªßa nh√† h√†ng l·∫©u b√≤ t∆∞∆°i Tian Long.\n"
             "**QUAN TR·ªåNG:** B·∫°n lu√¥n ∆∞u ti√™n th√¥ng tin t·ª´ t√†i li·ªáu ƒë∆∞·ª£c cung c·∫•p.\n\n"
             "üë§ **TH√îNG TIN KH√ÅCH:** {user_info}, {user_profile}\n"
             "üí¨ **B·ªêI C·∫¢NH:** {conversation_summary}\n" 
             "üñºÔ∏è **H√åNH ·∫¢NH:** {image_contexts} | üìÖ **NG√ÄY:** {current_date}\n\n"
             "üéØ **NGUY√äN T·∫ÆC V√ÄNG:**\n"
             "‚Ä¢ **Lu√¥n g·ªçi t√™n** t·ª´ user_info.name thay v√¨ 'anh/ch·ªã'\n"
             "‚Ä¢ **D·ª±a v√†o t√†i li·ªáu** - kh√¥ng b·ªãa ƒë·∫∑t\n"
             "‚Ä¢ Format Messenger: emoji + bullet, tr√°nh markdown ph·ª©c t·∫°p\n\n"
             "üçΩÔ∏è **ƒê·∫∂T B√ÄN - VALIDATION WORKFLOW:**\n"
             "1. Thu th·∫≠p 7 th√¥ng tin: t√™n, SƒêT, chi nh√°nh, ng√†y, gi·ªù, s·ªë ng∆∞·ªùi, sinh nh·∫≠t\n"
             "2. G·ªåI `validate_booking_info` ƒë·ªÉ ki·ªÉm tra\n"
             "3. N·∫øu validation_passed=false ‚Üí y√™u c·∫ßu kh√°ch s·ª≠a\n"
             "4. N·∫øu validation_passed=true ‚Üí x√°c nh·∫≠n v√† g·ªçi `book_table_reservation_test`\n\n"
             "‚ö†Ô∏è LU√îN validate tr∆∞·ªõc khi ƒë·∫∑t b√†n!\n\n"
             "üìö **T√ÄI LI·ªÜU THAM KH·∫¢O:**\n{context}\n"),
            MessagesPlaceholder(variable_name="messages")
        ]).partial(current_date=datetime.now, domain_context=domain_context)

        def get_combined_context(ctx: dict[str, Any]) -> str:
            import logging
            documents = ctx.get("documents", [])
            
            if documents:
                logging.info("üìÑ GENERATION DOCUMENTS ANALYSIS:")
                context_parts = []
                
                for i, doc in enumerate(documents[:10]):
                    if isinstance(doc, tuple) and len(doc) > 1 and isinstance(doc[1], dict):
                        doc_content = doc[1].get("content", "")
                        if doc_content:
                            context_parts.append(doc_content)
                            logging.info(f"   üìÑ Generation Context Doc {i+1}: {doc_content[:200]}...")
                            
                            if "chi nh√°nh" in doc_content.lower() or "branch" in doc_content.lower():
                                logging.info(f"   üéØ BRANCH INFO FOUND in Generation Context Doc {i+1}!")
                    else:
                        logging.info(f"   üìÑ Generation Context Doc {i+1}: Invalid format - {type(doc)}")
                
                if context_parts:
                    new_context = "\n\n".join(context_parts)
                    logging.info(f"   ‚úÖ Generated context from documents, length: {len(new_context)}")
                    return new_context
                else:
                    logging.warning("   ‚ö†Ô∏è No valid content found in documents!")
                    return ""
            else:
                logging.warning("   ‚ö†Ô∏è No documents found for context generation!")
                return ""

        runnable = (
            RunnablePassthrough.assign(context=lambda ctx: get_combined_context(ctx))
            | prompt
            | llm.bind_tools(all_tools)
        )
        super().__init__(runnable)
