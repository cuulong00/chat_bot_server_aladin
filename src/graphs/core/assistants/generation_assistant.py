from __future__ import annotations

from datetime import datetime
from typing import Any

from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.runnables import Runnable, RunnablePassthrough

from src.graphs.core.assistants.base_assistant import BaseAssistant


class GenerationAssistant(BaseAssistant):
    """The main assistant that generates the final response to the user."""
    def __init__(self, llm: Runnable, domain_context: str, all_tools: list):
        prompt = ChatPromptTemplate.from_messages([
            ("system",
             "Báº¡n lÃ  Vy â€“ trá»£ lÃ½ áº£o thÃ¢n thiá»‡n vÃ  chuyÃªn nghiá»‡p cá»§a nhÃ  hÃ ng láº©u bÃ² tÆ°Æ¡i Tian Long.\n"
             "**QUAN TRá»ŒNG:** Báº¡n luÃ´n Æ°u tiÃªn thÃ´ng tin tá»« tÃ i liá»‡u Ä‘Æ°á»£c cung cáº¥p.\n\n"
             "ï¿½ **THÃ”NG TIN KHÃCH HÃ€NG:**\n"
             "User info:\n<UserInfo>\n{user_info}\n</UserInfo>\n"
             "User profile:\n<UserProfile>\n{user_profile}\n</UserProfile>\n"
             "Conversation summary:\n<ConversationSummary>\n{conversation_summary}\n</ConversationSummary>\n"
             "Current date:\n<CurrentDate>\n{current_date}\n</CurrentDate>\n"
             "Image contexts:\n<ImageContexts>\n{image_contexts}\n</ImageContexts>\n\n"
             "ğŸ¯ **NGUYÃŠN Táº®C VÃ€NG:**\n"
             "â€¢ **LuÃ´n gá»i tÃªn** tá»« <UserInfo> thay vÃ¬ 'anh/chá»‹'\n"
             "â€¢ **Dá»±a vÃ o tÃ i liá»‡u** - khÃ´ng bá»‹a Ä‘áº·t\n"
             "â€¢ Format Messenger: emoji + bullet, trÃ¡nh markdown phá»©c táº¡p\n\n"
             "ğŸ½ï¸ **Äáº¶T BÃ€N - QUY TRÃŒNH:**\n"
             "1. Thu tháº­p Ä‘á»§ 7 thÃ´ng tin: tÃªn, SÄT, chi nhÃ¡nh, ngÃ y, giá», sá»‘ ngÆ°á»i, sinh nháº­t\n"
             "2. Hiá»ƒn thá»‹ tá»•ng há»£p thÃ´ng tin Ä‘á»ƒ khÃ¡ch xÃ¡c nháº­n\n"
             "3. Gá»i `book_table_reservation_test` khi khÃ¡ch xÃ¡c nháº­n Ä‘áº·t bÃ n\n\n"
             "ğŸ“š **TÃ€I LIá»†U THAM KHáº¢O:**\n<Context>\n{context}\n</Context>\n"),
            MessagesPlaceholder(variable_name="messages")
        ]).partial(current_date=datetime.now, domain_context=domain_context)

        def get_combined_context(ctx: dict[str, Any]) -> str:
            import logging
            documents = ctx.get("documents", [])
            
            if documents:
                logging.info("ğŸ“„ GENERATION DOCUMENTS ANALYSIS:")
                context_parts = []
                
                for i, doc in enumerate(documents[:10]):
                    if isinstance(doc, tuple) and len(doc) > 1 and isinstance(doc[1], dict):
                        doc_content = doc[1].get("content", "")
                        if doc_content:
                            context_parts.append(doc_content)
                            logging.info(f"   ğŸ“„ Generation Context Doc {i+1}: {doc_content[:200]}...")
                            
                            if "chi nhÃ¡nh" in doc_content.lower() or "branch" in doc_content.lower():
                                logging.info(f"   ğŸ¯ BRANCH INFO FOUND in Generation Context Doc {i+1}!")
                    else:
                        logging.info(f"   ğŸ“„ Generation Context Doc {i+1}: Invalid format - {type(doc)}")
                
                if context_parts:
                    new_context = "\n\n".join(context_parts)
                    logging.info(f"   âœ… Generated context from documents, length: {len(new_context)}")
                    return new_context
                else:
                    logging.warning("   âš ï¸ No valid content found in documents!")
                    return ""
            else:
                logging.warning("   âš ï¸ No documents found for context generation!")
                return ""

        runnable = (
            RunnablePassthrough.assign(context=lambda ctx: get_combined_context(ctx))
            | prompt
            | llm.bind_tools(all_tools)
        )
        super().__init__(runnable)
