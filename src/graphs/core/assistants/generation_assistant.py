from __future__ import annotations

from datetime import datetime
from typing import Any

from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.runnables import Runnable, RunnablePassthrough

from src.graphs.core.assistants.base_assistant import BaseAssistant
from src.utils.telemetry import time_step


class GenerationAssistant(BaseAssistant):
    """The main assistant that generates the final response to the user."""
    def __init__(self, llm: Runnable, domain_context: str, all_tools: list):
        config = {
            'assistant_name': 'Vy',
            'business_name': 'Nh√† h√†ng l·∫©u b√≤ t∆∞∆°i Tian Long',
            'booking_fields': 'T√™n, SƒêT, Chi nh√°nh, Ng√†y gi·ªù, S·ªë ng∆∞·ªùi, Sinh nh·∫≠t',
            'delivery_fields': 'T√™n, SƒêT, ƒê·ªãa ch·ªâ, Gi·ªù nh·∫≠n, Ng√†y nh·∫≠n',
            'delivery_menu': 'https://menu.tianlong.vn/',
            'booking_function': 'book_table_reservation'
        }
        prompt = ChatPromptTemplate.from_messages([
            ("system",
             # CORE ROLE DEFINITION
             "You are {assistant_name}, a professional sales consultant for {business_name}. "
             "Your mission: greet warmly, discover needs quickly, suggest suitable combos, upsell appropriately, drive bookings, and respond immediately. "
             "Always prioritize information from provided documents and context; never fabricate.\n\n"
             
             # CRITICAL ABSOLUTE RULES (Non-Negotiable)
             "üö® ABSOLUTE RULES - NEVER VIOLATE:\n"
             "‚Ä¢ DATA-ONLY RESPONSES: All information MUST be based on <Context>. Never create, guess, or use general food knowledge.\n"
             "‚Ä¢ NO PLACEHOLDERS: Never use [...], [to be updated], [list branches], [area name]. Fill with real info from context.\n"
             "‚Ä¢ IMMEDIATE ACTION: When you have 5 booking details (Name, Phone, Branch, Date/Time, People) ‚Üí CALL {booking_function} IMMEDIATELY\n"
             "‚Ä¢ FORBIDDEN PHRASES: 'I will check', 'let me verify', 'please wait', 'checking availability', 'will call back' = SERIOUS VIOLATION\n"
             "‚Ä¢ ONLY ALLOWED: Call tool ‚Üí Report result ('Successfully booked' or 'Error occurred')\n\n"
             
             # USER CONTEXT
             "üë§ User Context:\n"
             "<UserInfo>{user_info}</UserInfo>\n"
             "<UserProfile>{user_profile}</UserProfile>\n"
             "<ConversationSummary>{conversation_summary}</ConversationSummary>\n"
             "<CurrentDate>{current_date}</CurrentDate>\n"
             "<ImageContexts>{image_contexts}</ImageContexts>\n\n"
             
             # COMMUNICATION PROTOCOL
             "üé≠ COMMUNICATION STANDARDS:\n"
             "‚Ä¢ ADDRESSING: NEVER use 'b·∫°n'. Always use 'anh/ch·ªã'. When name known, use 'anh Nam/ch·ªã Lan'\n"
             "‚Ä¢ TONE: Professional but warm, proactive, benefit-focused\n"
             "‚Ä¢ LANGUAGE: Avoid 'D·∫° ƒë∆∞·ª£c r·ªìi ·∫°', 'OK ·∫°'. Use 'V√¢ng ·∫°', 'Ch·∫Øc ch·∫Øn ·∫°', 'Em ghi nh·∫≠n r·ªìi ·∫°'\n"
             "‚Ä¢ CTA REQUIRED: Always end with clear next-step question (time/branch/people count)\n"
             "‚Ä¢ PERSONALIZE: Use names when available, brief but thorough\n\n"
             
             # CORE WORKFLOWS
             "ÔøΩ KEY WORKFLOWS:\n\n"
             
             "1. GREETING SCRIPT (first message priority):\n"
             "Format: Greeting + Brief intro + Specific help offer + Closing question (CTA)\n"
             "Example: 'Ch√†o anh/ch·ªã ·∫°, em l√† {assistant_name} t·ª´ {business_name}. Em h·ªó tr·ª£ ƒë·∫∑t b√†n, combo ∆∞u ƒë√£i v√† ti·ªác sinh nh·∫≠t. Anh/ch·ªã d·ª± ƒë·ªãnh d√πng b·ªØa m·∫•y gi·ªù v√† cho bao nhi√™u ng∆∞·ªùi ·∫°?'\n\n"
             
             "2. MENU REQUESTS (direct response):\n"
             "When asked 'menu', 'th·ª±c ƒë∆°n', 'xem menu' ‚Üí IMMEDIATELY send: {delivery_menu_link}\n"
             "Follow with appropriate CTA\n\n"
             
             "3. BRANCH VERIFICATION (immediate response):\n"
             "When customer mentions location ‚Üí IMMEDIATELY check <Context> and CONFIRM availability\n"
             "If no branch exists ‚Üí CONFIRM IMMEDIATELY + LIST available branches in standard format\n"
             "NEVER say 'let me check' - information is already in context\n\n"
             
             "4. BOOKING PROCESS:\n"
             "Collect: Branch ‚Üí {required_booking_fields}\n"
             "When complete ‚Üí Call {booking_function} immediately\n"
             "Report result + suggest next steps\n\n"
             
             "5. FOOD RECOMMENDATIONS:\n"
             "‚Ä¢ Base on <UserProfile> + current context + <ConversationSummary>\n"
             "‚Ä¢ Only suggest items that exist in <Context>\n"
             "‚Ä¢ Explain why suitable (spice level, price, portion, group fit)\n"
             "‚Ä¢ Offer alternatives when requested item unavailable\n"
             "‚Ä¢ Save preferences with save_user_preference when detected\n\n"
             
             # SAFETY & ERROR HANDLING
             "üõ°Ô∏è SAFETY PROTOCOLS:\n"
             "‚Ä¢ Empty <Context> ‚Üí Send menu link {delivery_menu_link} + ask for booking details\n"
             "‚Ä¢ Unknown items ‚Üí 'Em ch∆∞a c√≥ th√¥ng tin v·ªÅ m√≥n n√†y' + menu link\n"
             "‚Ä¢ < 2 suitable options found ‚Üí Send menu link + ask preferences (spicy/mild, group size)\n"
             "‚Ä¢ Link format: 'üåê https://menu.tianlong.vn' (no markdown)\n"
             "‚Ä¢ Food display: Each item on separate line with emoji\n\n"
             
             # DELIVERY SERVICE
             "üöö DELIVERY WORKFLOW:\n"
             "Available service - collect: {required_delivery_fields}\n"
             "Menu link: 'üåê https://menu.tianlong.vn'\n"
             "Fees calculated by delivery platform\n\n"
             
             # TOOLS USAGE
             "üß† TOOL USAGE:\n"
             "‚Ä¢ Detect preferences ('th√≠ch', 'y√™u', '∆∞a', 'th∆∞·ªùng', etc.) ‚Üí save_user_preference\n"
             "‚Ä¢ Save before responding to content\n\n"
             
             # REFERENCE DATA
             "üìö Reference Data:\n<Context>{context}</Context>\n\n"
             
             # OUTPUT FORMAT
             "üì§ RESPONSE FORMAT:\n"
             "‚Ä¢ Vietnamese language, professional sales tone\n"
             "‚Ä¢ Always end with clear CTA\n"
             "‚Ä¢ Proactive suggestions for upsell opportunities\n"
             "‚Ä¢ Show genuine care for customer needs\n"
             "‚Ä¢ Use emojis appropriately, not excessively\n"
             "‚Ä¢ Brief summaries with format: Emoji + Label + Value\n"
             "‚Ä¢ Missing info ‚Üí 'C·∫ßn b·ªï sung', not 'n·∫øu c√≥'\n"
             "‚Ä¢ Time normalization: 't·ªëi nay' ‚Üí specific dd/mm/yyyy format based on <CurrentDate>"
             ) ,
            MessagesPlaceholder(variable_name="messages")
        ]).partial(
            current_date=datetime.now,
            assistant_name=config.get('assistant_name', 'Tr·ª£ l√Ω'),
            business_name=config.get('business_name', 'Nh√† h√†ng'),
            required_booking_fields=config.get('booking_fields', 'T√™n, SƒêT, Chi nh√°nh, Ng√†y gi·ªù, S·ªë ng∆∞·ªùi'),
            required_delivery_fields=config.get('delivery_fields', 'T√™n, SƒêT, ƒê·ªãa ch·ªâ, Gi·ªù nh·∫≠n'),
            delivery_menu_link=config.get('delivery_menu', 'Link menu'),
            booking_function=config.get('booking_function', 'book_table_reservation'),
            domain_context=domain_context
        )

        def get_combined_context(ctx: dict[str, Any]) -> str:
            import logging
            documents = ctx.get("documents", [])
            image_contexts = ctx.get("image_contexts", [])
            context_parts = []
            # X·ª≠ l√Ω image contexts tr∆∞·ªõc (∆∞u ti√™n th√¥ng tin t·ª´ ·∫£nh)
            if image_contexts:
                logging.info("üñºÔ∏è GENERATION IMAGE CONTEXTS ANALYSIS:")
                for i, img_context in enumerate(image_contexts):
                    if img_context and isinstance(img_context, str):
                        context_parts.append(f"**TH√îNG TIN T·ª™ H√åNH ·∫¢NH {i+1}:**\n{img_context}")
                        logging.info(f"   üñºÔ∏è Generation Image Context {i+1}: {img_context[:200]}...")
                logging.info(f"   ‚úÖ Added {len(image_contexts)} image contexts")
            # X·ª≠ l√Ω documents v√† tr√≠ch xu·∫•t image URLs
            if documents:
                logging.info("üìÑ GENERATION DOCUMENTS ANALYSIS:")
                
                # Debug: Check document structure
                logging.info(f"   üìä Total documents: {len(documents)}")
                for i, doc in enumerate(documents[:3]):
                    logging.info(f"   üìÑ Doc {i+1} type: {type(doc)}")
                    if isinstance(doc, tuple):
                        logging.info(f"   üìÑ Doc {i+1} tuple length: {len(doc)}")
                        if len(doc) > 0:
                            logging.info(f"   üìÑ Doc {i+1}[0] type: {type(doc[0])}")
                            logging.info(f"   üìÑ Doc {i+1}[0] value: {doc[0]}")
                        if len(doc) > 1:
                            logging.info(f"   üìÑ Doc {i+1}[1] type: {type(doc[1])}")
                            if isinstance(doc[1], dict):
                                keys = list(doc[1].keys())
                                logging.info(f"   üìÑ Doc {i+1}[1] keys: {keys}")
                                if 'content' in doc[1]:
                                    content_preview = doc[1]['content'][:100] + "..." if len(doc[1]['content']) > 100 else doc[1]['content']
                                    logging.info(f"   üìÑ Doc {i+1} content preview: {content_preview}")
                
                # Extract image URLs from document metadata for display
                image_urls_found = []
                for i, doc in enumerate(documents[:10]):
                    if isinstance(doc, tuple) and len(doc) > 1 and isinstance(doc[1], dict):
                        doc_dict = doc[1]
                        image_url = None
                        if "image_url" in doc_dict:
                            image_url = doc_dict["image_url"]
                        elif "metadata" in doc_dict and isinstance(doc_dict["metadata"], dict):
                            image_url = doc_dict["metadata"].get("image_url")
                        if image_url:
                            combo_name = doc_dict.get("combo_name") or doc_dict.get("metadata", {}).get("title", "Combo")
                            image_urls_found.append(f"üì∏ {combo_name}: {image_url}")
                            logging.info(f"   üñºÔ∏è Found image URL: {combo_name} -> {image_url}")
                if image_urls_found:
                    context_parts.append("**C√ÅC ·∫¢NH COMBO HI·ªÜN C√ì:**\n" + "\n".join(image_urls_found))
                    logging.info(f"   ‚úÖ Added {len(image_urls_found)} image URLs to context")
                for i, doc in enumerate(documents[:10]):
                    if isinstance(doc, tuple) and len(doc) > 1 and isinstance(doc[1], dict):
                        doc_content = doc[1].get("content", "")
                        if doc_content:
                            context_parts.append(doc_content)
                            logging.info(f"   üìÑ Generation Context Doc {i+1}: {doc_content[:200]}...")
                            if "chi nh√°nh" in doc_content.lower() or "branch" in doc_content.lower():
                                logging.info(f"   üéØ BRANCH INFO FOUND in Generation Context Doc {i+1}!")
                    else:
                        logging.info(f"   üìÑ Generation Context Doc {i+1}: Invalid format - {type(doc)}")
            
            if context_parts:
                new_context = "\n\n".join(context_parts)
                logging.info(f"   ‚úÖ Generated combined context with {len(image_contexts)} images + {len(documents) if documents else 0} docs, total length: {len(new_context)}")
                return new_context
            else:
                logging.warning("   ‚ö†Ô∏è No valid content found in documents or image contexts!")
                return ""

        def get_name_if_known(ctx: dict[str, Any]) -> str:
            try:
                profile = ctx.get("user_profile") or {}
                info = ctx.get("user_info") or {}
                name = (
                    (profile.get("name") or "").strip()
                    or (((info.get("first_name") or "").strip() + (" " + info.get("last_name").strip() if info.get("last_name") else "")).strip())
                    or (info.get("name") or "").strip()
                )
                return (" " + name) if name else ""
            except Exception:
                return ""

        with_tools = (
            RunnablePassthrough.assign(
                context=lambda ctx: get_combined_context(ctx),
                name_if_known=lambda ctx: get_name_if_known(ctx),
            )
            | prompt
            | llm.bind_tools(all_tools)
        )
        no_tools = (
            RunnablePassthrough.assign(
                context=lambda ctx: get_combined_context(ctx),
                name_if_known=lambda ctx: get_name_if_known(ctx),
            )
            | prompt
            | llm
        )

        # Expose for conditional use in __call__
        self._with_tools_runnable = with_tools
        self._no_tools_runnable = no_tools
        self._prompt = prompt
        self._all_tools = all_tools
        super().__init__(with_tools)

    def __call__(self, state: dict, config: dict) -> Any:
        import logging
        # Decide whether to enable tools: disable for pure menu/food intent to allow hallucination grading
        def _text_from_messages(msgs: Any) -> str:
            try:
                if isinstance(msgs, list) and msgs:
                    last = msgs[-1]
                    if isinstance(last, dict):
                        return (last.get("content") or last.get("text") or "").lower()
                    return getattr(last, "content", "").lower()
                return str(msgs or "").lower()
            except Exception:
                return ""

        text = state.get("question") or _text_from_messages(state.get("messages"))
        keywords = ["menu", "th·ª±c ƒë∆°n", "m√≥n", "combo", "gi√°", "∆∞u ƒë√£i", "khuy·∫øn m√£i"]
        is_menu_intent = any(k in (text or "") for k in keywords)
        # Detect explicit user preference expressions (e.g. 'th√≠ch', 'y√™u', '∆∞a', ...)
        preference_keywords = ["th√≠ch", "y√™u", "∆∞a", "th∆∞·ªùng", "hay", "lu√¥n", "mu·ªën", "c·∫ßn", "sinh nh·∫≠t"]
        is_preference_intent = any(p in (text or "") for p in preference_keywords)
        datasource = (state.get("datasource") or "").lower()
        # Keep previous behavior (disable tools for pure menu intent on vectorstore) but
        # always enable tools when a preference is detected so save_user_preference can be called.
        use_tools = is_preference_intent or not (is_menu_intent and datasource == "vectorstore")
        if not use_tools:
            logging.info("üõ°Ô∏è GenerationAssistant: Disabling tools for menu intent to ensure hallucination grading.")

        runnable = self._with_tools_runnable if use_tools else self._no_tools_runnable

        prompt_data = self.binding_prompt(state)
        full_state = {**state, **prompt_data}
        try:
            result = runnable.invoke(full_state, config)
            if self._is_valid_response(result):
                return result
            logging.warning("‚ö†Ô∏è GenerationAssistant: Empty/invalid response, using fallback.")
            return self._create_fallback_response(state)
        except Exception as e:
            logging.error(f"‚ùå GenerationAssistant: Exception during invoke: {e}")
            return self._create_fallback_response(state)
