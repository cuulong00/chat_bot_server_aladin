#!/usr/bin/env python3
"""
Test script to validate DocGrader improvements for menu queries.
This script simulates the exact scenario from the log where menu documents were incorrectly marked as irrelevant.
"""

import logging
from datetime import datetime

from langchain_google_genai import ChatGoogleGenerativeAI
from src.graphs.core.assistants.doc_grader_assistant import DocGraderAssistant
from src.graphs.state.state import RagState

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s [%(levelname)s] %(message)s'
)

# Test documents from the actual log
test_documents = [
    {
        "content": "### Khi khÃ¡ch phÃ n nÃ n vá» tÃ­nh riÃªng tiá»n nÆ°á»›c láº©u\n\"Dáº¡ em cáº£m Æ¡n anh/chá»‹ Ä‘Ã£ gÃ³p Ã½! Tian long tÃ­nh riÃªng nÆ°á»›c láº©u vÃ  nhÃ¢n nhÃºng vÃ¬ má»—i pháº§n cÃ³ giÃ¡ trá»‹ nguyÃªn liá»‡u vÃ  giÃ¡ thÃ nh khÃ¡c nhau. Viá»‡c nÃ y giÃºp khÃ¡ch hÃ ng thoáº£i mÃ¡i lá»±a chá»n theo sá»Ÿ thÃ­ch vÃ  ngÃ¢n sÃ¡ch cá»§a mÃ¬nh. Mong anh/chá»‹ hiá»ƒu vÃ  tiáº¿p tá»¥c á»§ng há»™ nhÃ  hÃ ng áº¡.\"",
        "expected": "no",  # Should be no - not menu related
        "description": "Complaint handling - should be irrelevant to menu query"
    },
    {
        "content": "### Nhá»¯ng cÃ¢u há»i vá» mÃ³n Äƒn\n\n#### Láº©u bÃ² tÆ°Æ¡i Triá»u ChÃ¢u cÃ³ gÃ¬ Ä‘áº·c biá»‡t?\nLáº©u bÃ² tÆ°Æ¡i Triá»u ChÃ¢u táº¡i Tian Long cÃ³ Ä‘áº·c Ä‘iá»ƒm \"TÆ°Æ¡i nhÆ°ng khÃ´ng tanh, ngá»t nhÆ°ng khÃ´ng ngáº¥y, non nhÆ°ng khÃ´ng sá»‘ng\". NÆ°á»›c láº©u Ä‘Æ°á»£c náº¥u tá»« cÃ´ng thá»©c gia truyá»n, káº¿t há»£p 36 vá»‹ thuá»‘c quÃ½ cÃ³ tÃ¡c dá»¥ng thanh lá»c cÆ¡ thá»ƒ. Thá»‹t bÃ² Ä‘Æ°á»£c tinh tuyá»ƒn vá»›i chá»‰ 37% tá»« con bÃ² Ä‘áº¡t tiÃªu chuáº©n, trong Ä‘Ã³ 1% lÃ  pháº§n thá»‹t ngon nháº¥t (Diá»m thÄƒn, GÃ¹ hoa...).",
        "expected": "yes",  # Should be yes - directly about food/dishes
        "description": "Food FAQ - should be highly relevant to menu query"
    },
    {
        "content": "Tian Long lÃ  chuá»—i nhÃ  hÃ ng láº©u bÃ² tÆ°Æ¡i theo phong cÃ¡ch Triá»u ChÃ¢u, vá»›i khÃ´ng gian sang trá»ng vÃ  thá»±c Ä‘Æ¡n Ä‘a dáº¡ng cÃ³ lá»£i cho sá»©c khá»e. ThÆ°Æ¡ng hiá»‡u ná»•i báº­t vá»›i cÃ¡c mÃ³n láº©u bÃ² tÆ°Æ¡i cháº¥t lÆ°á»£ng cao, tháº£o má»™c quÃ½ vÃ  dimsum thá»§ cÃ´ng tá»« nghá»‡ nhÃ¢n áº©m thá»±c.",
        "expected": "yes",  # Should be yes - mentions restaurant, menu diversity, food items
        "description": "Restaurant intro mentioning diverse menu - should be relevant"
    },
    {
        "content": "### Hiá»ƒu tá»« viáº¿t táº¯t\n- \"DC\", \"Ä‘/c\", \"dchi\" = Ä‘á»‹a chá»‰\n- \"a\" = anh\n- \"c\" = chá»‹\n- \"con sá»‘ + nl\" (3nl) = sá»‘ ngÆ°á»i lá»›n\n- \"con sá»‘ + te\" (2te) = sá»‘ tráº» em",
        "expected": "no",  # Should be no - abbreviations, not menu related
        "description": "Abbreviations guide - should be irrelevant to menu query"
    },
    {
        "content": "### Vá» tráº» em\n\"Dáº¡ bÃªn em lÃ  hÃ¬nh thá»©c gá»i mÃ³n nÃªn mÃ¬nh cÃ³ thá»ƒ gá»i theo sá»©c Äƒn cá»§a cÃ¡c bÃ© áº¡. BÃªn em cÅ©ng cÃ³ ráº¥t nhiá»u mÃ³n phÃ¹ há»£p cho cÃ¡c bÃ© nhÆ°: khoai tÃ¢y chiÃªn, chÃ¢n gÃ , dimsum...\"",
        "expected": "yes",  # Should be yes - mentions specific dishes for children
        "description": "Children-friendly dishes - should be relevant to menu query"
    }
]

# Test query that failed in the log
test_query = "hÃ£y cho anh danh sÃ¡ch cÃ¡c mÃ³n"

def test_docgrader_with_improved_logic():
    """Test DocGrader with improved menu detection logic"""
    
    print(f"\nğŸ§ª TESTING DOCGRADER IMPROVEMENTS")
    print(f"ğŸ“‹ Test Query: '{test_query}'")
    print(f"ğŸ“Š Testing {len(test_documents)} documents")
    print("="*80)
    
    # Initialize DocGrader with test LLM
    try:
        llm = ChatGoogleGenerativeAI(
            model="gemini-1.5-flash",
            temperature=0,
            max_tokens=None,
            timeout=None,
            max_retries=2,
        )
        
        docgrader = DocGraderAssistant(
            llm=llm,
            domain_context="Vietnamese restaurant chatbot for Tian Long hotpot chain"
        )
        
        print(f"âœ… DocGrader initialized successfully")
        
    except Exception as e:
        print(f"âŒ Failed to initialize DocGrader: {e}")
        return
    
    # Test each document
    correct_predictions = 0
    total_tests = len(test_documents)
    
    for i, test_doc in enumerate(test_documents, 1):
        print(f"\nğŸ“„ Test {i}/{total_tests}: {test_doc['description']}")
        print(f"ğŸ“ Content preview: {test_doc['content'][:100]}...")
        print(f"ğŸ¯ Expected: {test_doc['expected']}")
        
        try:
            # Create state for testing
            test_state = RagState(
                messages=test_query,
                document=test_doc['content'],
                user={
                    'user_info': {'user_id': 'test_user', 'name': 'Test User'},
                    'user_profile': {'summary': 'Test user preferences'}
                },
                conversation_summary="User asking about restaurant menu",
                user_info={'user_id': 'test_user', 'name': 'Test User'},
                user_profile={'summary': 'Test user preferences'}
            )
            
            # Get DocGrader prediction
            config = {"run_id": "test_run"}
            result = docgrader(test_state, config)
            actual_score = result.binary_score.lower()
            
            print(f"ğŸ¤– Actual: {actual_score}")
            
            # Check if prediction matches expectation
            is_correct = actual_score == test_doc['expected']
            if is_correct:
                print(f"âœ… CORRECT")
                correct_predictions += 1
            else:
                print(f"âŒ INCORRECT - Expected: {test_doc['expected']}, Got: {actual_score}")
                
        except Exception as e:
            print(f"ğŸ’¥ Error testing document {i}: {e}")
            import traceback
            traceback.print_exc()
    
    # Final results
    print("\n" + "="*80)
    print(f"ğŸ“Š FINAL RESULTS:")
    print(f"âœ… Correct predictions: {correct_predictions}/{total_tests}")
    print(f"ğŸ“ˆ Accuracy: {(correct_predictions/total_tests)*100:.1f}%")
    
    if correct_predictions >= total_tests * 0.8:  # 80% accuracy threshold
        print(f"ğŸ‰ SUCCESS: DocGrader improvements are working well!")
    else:
        print(f"âš ï¸  WARNING: DocGrader needs further improvements")
        
    return correct_predictions, total_tests

if __name__ == "__main__":
    test_docgrader_with_improved_logic()
