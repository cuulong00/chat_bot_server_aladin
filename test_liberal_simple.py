#!/usr/bin/env python3
"""
Simple test for liberal DocGrader using correct calling pattern.
"""

import sys
import os
from pathlib import Path

# Add project root to path
project_root = Path(__file__).parent
sys.path.append(str(project_root))

from dotenv import load_dotenv
load_dotenv()

# Sample documents from your log
SAMPLE_DOCUMENTS = [
    "Dimsum háº¥p Ä‘Æ°á»£c lÃ m thá»§ cÃ´ng vá»›i nguyÃªn liá»‡u tÆ°Æ¡i ngon, bao gá»“m hÃ¡ cáº£o tÃ´m, xÃ­u máº¡i, bÃ¡nh bao nhÃ¢n thá»‹t.",
    "KhÃ¡ch hÃ ng complain vá» láº©u bÃ² khÃ´ng Ä‘á»§ gia vá»‹. ÄÃ£ xá»­ lÃ½ báº±ng cÃ¡ch thÃªm nÆ°á»›c máº¯m vÃ  á»›t.",  
    "Tian Long cÃ³ tá»•ng cá»™ng 15 chi nhÃ¡nh trÃªn toÃ n quá»‘c, phá»¥c vá»¥ hÆ¡n 10,000 khÃ¡ch hÃ ng má»—i thÃ¡ng.",
    "ChÃ­nh sÃ¡ch Ä‘áº·t ship: Thu tháº­p thÃ´ng tin Ä‘á»‹a chá»‰, xÃ¡c nháº­n Ä‘Æ¡n hÃ ng, giao hÃ ng trong 30-45 phÃºt.",
    "CÃ´ng ty Ä‘Æ°á»£c thÃ nh láº­p nÄƒm 2010, chuyÃªn vá» áº©m thá»±c Trung Hoa cao cáº¥p.",
    "BÃ¡o cÃ¡o tÃ i chÃ­nh quÃ½ 3 nÄƒm 2024 cho tháº¥y doanh thu tÄƒng 15% so vá»›i cÃ¹ng ká»³ nÄƒm trÆ°á»›c.",
    "ThÃ´ng tin weather forecast cho HÃ  Ná»™i ngÃ y mai: náº¯ng, nhiá»‡t Ä‘á»™ 25-30Â°C."
]

MENU_QUERY = "hÃ£y cho anh danh sÃ¡ch cÃ¡c mÃ³n"

def test_liberal_grader():
    """Test new liberal grader using correct calling pattern."""
    
    print("ğŸ§ª TESTING NEW LIBERAL DOCGRADER")
    print("=" * 50)
    
    try:
        from src.graphs.core.assistants.doc_grader_assistant import DocGraderAssistant
        from langchain_google_genai import ChatGoogleGenerativeAI
        from langchain_core.runnables import RunnableConfig
        
        # Initialize LLM
        llm = ChatGoogleGenerativeAI(
            model="gemini-1.5-flash",
            temperature=0.1,
            api_key=os.getenv("GOOGLE_API_KEY")
        )
        
        # Initialize grader
        grader = DocGraderAssistant(llm, "Vietnamese restaurant (Tian Long) customer service chatbot")
        print(f"âœ… DocGrader initialized successfully!")
        
        # Test config
        config = RunnableConfig()
        
        print(f"\nğŸ“ Testing query: '{MENU_QUERY}'")
        print("-" * 50)
        
        relevant_count = 0
        total_docs = len(SAMPLE_DOCUMENTS)
        
        for i, doc_content in enumerate(SAMPLE_DOCUMENTS):
            try:
                # Create state matching the graph pattern
                state = {
                    "document": doc_content,
                    "messages": MENU_QUERY,
                    "user": {"user_id": "test_user"}
                }
                
                # Call grader
                result = grader(state, config)
                
                decision = result.binary_score.lower() if hasattr(result, 'binary_score') else 'unknown'
                
                if decision == 'yes':
                    relevant_count += 1
                    status = "âœ… RELEVANT"
                else:
                    status = "âŒ NOT RELEVANT"
                
                doc_preview = doc_content[:60] + "..." if len(doc_content) > 60 else doc_content
                print(f"  Doc {i+1}: [{status}] {doc_preview}")
                
            except Exception as e:
                print(f"  Doc {i+1}: [ERROR] {e}")
        
        # Calculate results
        relevance_rate = relevant_count / total_docs * 100
        print(f"\nğŸ“Š RESULTS:")
        print(f"   Relevant Documents: {relevant_count}/{total_docs}")
        print(f"   Relevance Rate: {relevance_rate:.1f}%")
        
        # Assessment
        if relevance_rate >= 75:
            print(f"   ğŸ‰ EXCELLENT! Liberal approach working well")
        elif relevance_rate >= 60:
            print(f"   âœ… GOOD! Significant improvement")  
        elif relevance_rate >= 40:
            print(f"   ğŸ¤” MODERATE - Some improvement")
        else:
            print(f"   ğŸš¨ POOR - Still too restrictive")
            
        print(f"\nğŸ¯ EXPECTED FOR MENU QUERIES:")
        print(f"   Target: 70-85% (most restaurant docs should be relevant)")
        print(f"   Only weather doc should be irrelevant")
        
        return relevance_rate
        
    except Exception as e:
        print(f"âŒ Test failed: {e}")
        import traceback
        traceback.print_exc()
        return 0

def show_analysis():
    """Show the improvement analysis."""
    
    print(f"\nğŸ“‹ DOCGRADER IMPROVEMENT ANALYSIS")
    print("=" * 50)
    
    print(f"ğŸ” ORIGINAL ISSUES:")
    print(f"   â€¢ Overly complex prompt (>1000 words)")
    print(f"   â€¢ Too many conflicting rules")
    print(f"   â€¢ Conservative 'when in doubt, exclude' approach")
    print(f"   â€¢ Only 25% relevance for menu queries")
    
    print(f"\nğŸ”§ LIBERAL APPROACH FIXES:")
    print(f"   â€¢ Simplified prompt (~300 words)")
    print(f"   â€¢ Clear liberal philosophy: 'When in doubt, choose yes'")  
    print(f"   â€¢ Restaurant context bonus")
    print(f"   â€¢ Target: 80% of restaurant docs relevant")
    
    print(f"\nğŸ“Š EXPECTED BENEFITS:")
    print(f"   â€¢ Menu queries: 25% â†’ 75%+ relevance")
    print(f"   â€¢ More consistent responses")
    print(f"   â€¢ Fewer incomplete answers")
    print(f"   â€¢ Better user experience")

if __name__ == "__main__":
    print("ğŸ”§ DOCGRADER LIBERAL APPROACH TEST")
    print("=" * 50)
    
    # Run test
    relevance_rate = test_liberal_grader()
    
    # Show analysis  
    show_analysis()
    
    print(f"\nğŸ TEST COMPLETE!")
    if relevance_rate >= 60:
        print(f"   âœ… Liberal DocGrader is working!")
        print(f"   ğŸ“ˆ Ready for production testing")
    else:
        print(f"   âš ï¸  May need further adjustments")
        print(f"   ğŸ”§ Consider confidence-based or no-grader approach")
