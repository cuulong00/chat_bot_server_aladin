#!/usr/bin/env python3
"""
Simple test for new liberal DocGrader.
"""

import sys
import asyncio
from pathlib import Path

# Add project root to path
project_root = Path(__file__).parent
sys.path.append(str(project_root))

# Sample problematic documents from your log
SAMPLE_DOCUMENTS = [
    "Dimsum h·∫•p ƒë∆∞·ª£c l√†m th·ªß c√¥ng v·ªõi nguy√™n li·ªáu t∆∞∆°i ngon, bao g·ªìm h√° c·∫£o t√¥m, x√≠u m·∫°i, b√°nh bao nh√¢n th·ªãt.",
    "Kh√°ch h√†ng complain v·ªÅ l·∫©u b√≤ kh√¥ng ƒë·ªß gia v·ªã. ƒê√£ x·ª≠ l√Ω b·∫±ng c√°ch th√™m n∆∞·ªõc m·∫Øm v√† ·ªõt.",
    "Tian Long c√≥ t·ªïng c·ªông 15 chi nh√°nh tr√™n to√†n qu·ªëc, ph·ª•c v·ª• h∆°n 10,000 kh√°ch h√†ng m·ªói th√°ng.",
    "Ch√≠nh s√°ch ƒë·∫∑t ship: Thu th·∫≠p th√¥ng tin ƒë·ªãa ch·ªâ, x√°c nh·∫≠n ƒë∆°n h√†ng, giao h√†ng trong 30-45 ph√∫t.",
    "C√¥ng ty ƒë∆∞·ª£c th√†nh l·∫≠p nƒÉm 2010, chuy√™n v·ªÅ ·∫©m th·ª±c Trung Hoa cao c·∫•p.",
    "B√°o c√°o t√†i ch√≠nh qu√Ω 3 nƒÉm 2024 cho th·∫•y doanh thu tƒÉng 15% so v·ªõi c√πng k·ª≥ nƒÉm tr∆∞·ªõc.",
    "Th√¥ng tin weather forecast cho H√† N·ªôi ng√†y mai: n·∫Øng, nhi·ªát ƒë·ªô 25-30¬∞C."
]

MENU_QUERIES = [
    "h√£y cho anh danh s√°ch c√°c m√≥n",
    "menu c√≥ nh·ªØng m√≥n g√¨", 
    "c√≥ m√≥n n√†o ngon kh√¥ng"
]

async def test_liberal_grader():
    """Test new liberal grader approach."""
    
    print("üß™ TESTING NEW LIBERAL GRADER")
    print("=" * 50)
    
    try:
        from src.graphs.core.assistants.doc_grader_assistant import DocGraderAssistant
        from langchain_google_genai import ChatGoogleGenerativeAI
        import os
        from dotenv import load_dotenv
        
        load_dotenv()
        
        # Initialize LLM
        llm = ChatGoogleGenerativeAI(
            model="gemini-1.5-flash", 
            temperature=0.1,
            api_key=os.getenv("GOOGLE_API_KEY")
        )
        
        # Initialize new grader
        grader = DocGraderAssistant(llm, "Vietnamese restaurant (Tian Long) customer service chatbot")
        
        print(f"‚úÖ DocGrader initialized successfully!")
        print(f"üìÑ Testing with {len(SAMPLE_DOCUMENTS)} documents")
        print(f"üîç Testing with {len(MENU_QUERIES)} queries")
        
        total_relevant = 0
        total_tests = 0
        
        for query in MENU_QUERIES:
            print(f"\nüìù Query: '{query}'")
            print("-" * 40)
            
            relevant_count = 0
            
            for i, doc in enumerate(SAMPLE_DOCUMENTS):
                try:
                    result = await grader.agrade_document(
                        document=doc,
                        messages=query,
                        conversation_summary="User asking about restaurant menu"
                    )
                    
                    decision = result.get('binary_decision', 'unknown')
                    if decision == 'yes':
                        relevant_count += 1
                        total_relevant += 1
                    
                    total_tests += 1
                    doc_preview = doc[:60] + "..." if len(doc) > 60 else doc
                    print(f"  Doc {i+1}: [{decision.upper()}] {doc_preview}")
                    
                except Exception as e:
                    print(f"  Doc {i+1}: [ERROR] {e}")
                    
            relevance_rate = relevant_count / len(SAMPLE_DOCUMENTS) * 100
            print(f"\n  üìä Query Relevance: {relevant_count}/{len(SAMPLE_DOCUMENTS)} ({relevance_rate:.1f}%)")
        
        # Overall statistics
        overall_rate = total_relevant / total_tests * 100
        print(f"\nüéØ OVERALL RESULTS:")
        print(f"   Total Relevant: {total_relevant}/{total_tests} ({overall_rate:.1f}%)")
        
        if overall_rate < 50:
            print("   üö® STILL TOO RESTRICTIVE - Need more liberal approach")
        elif overall_rate >= 70:
            print("   ‚úÖ EXCELLENT - Good liberal approach!")
        else:
            print("   ü§î MODERATE - Some improvement but may need tweaks")
            
    except Exception as e:
        print(f"‚ùå Test failed: {e}")
        import traceback
        traceback.print_exc()

def show_recommendations():
    """Show improvement recommendations."""
    
    print("\nüéØ DOCGRADER IMPROVEMENT SUMMARY")
    print("=" * 50)
    
    print("üìù PROBLEM ANALYSIS:")
    print("   ‚Ä¢ Original prompt was too complex (>1000 words)")
    print("   ‚Ä¢ Too many specific rules confused the LLM") 
    print("   ‚Ä¢ Conservative approach caused false negatives")
    
    print("\nüîß SOLUTION IMPLEMENTED:")
    print("   ‚Ä¢ Simplified prompt to ~300 words")
    print("   ‚Ä¢ Clear liberal philosophy: 'When in doubt, choose yes'")
    print("   ‚Ä¢ Restaurant context bonus scoring")
    print("   ‚Ä¢ Target: 80% of restaurant docs should be relevant")
    
    print("\nüìä EXPECTED IMPROVEMENTS:")
    print("   ‚Ä¢ Menu query success: 65% ‚Üí 90%+")
    print("   ‚Ä¢ Consistency: Much more predictable")
    print("   ‚Ä¢ Processing speed: Slightly faster")
    print("   ‚Ä¢ False negatives: Dramatically reduced")
    
    print("\nüöÄ NEXT STEPS IF NEEDED:")
    print("   1. Confidence-based grader (scores 0-1 vs binary)")
    print("   2. No-grader approach (semantic ranking only)")
    print("   3. Hybrid approach (simple rules + LLM)")

if __name__ == "__main__":
    print("üîß DOCGRADER LIBERAL APPROACH TEST")
    print("=" * 50)
    
    # Test new approach  
    asyncio.run(test_liberal_grader())
    
    # Show recommendations
    show_recommendations()
    
    print(f"\nüèÅ Test complete! Check results above.")
    print(f"   If relevance rate < 70%, we may need further adjustments.")
